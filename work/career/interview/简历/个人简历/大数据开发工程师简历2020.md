# 大数据开发工程师简历 2020


## 基本信息

电话：13409736469，邮箱： 13409736469@163.com
微信：TomAndersen
生日：26 岁，性别：男
现居城市：湖北省黄冈市，目前学业完成情况：研一在读

照片：xxx
个人主页： https://blog.tomandersen.cn/
Github： https://github.com/TomAndersen0714
博客： https://blog.csdn.net/TomAndersen

求职意向：数据开发相关

## 教育经历

华中科技大学 - 计算机技术硕士计算机科学与技术学院，2019.08 - 2021.05
中国地质大学（武汉） - 空间信息与数字技术本科计算机科学与技术学院，2015.08 - 2019.05

## 专业技能

熟悉 Java 语法，了解 JVM 以及 Java 集合等基本框架
了解常用的设计模式
熟悉 Linux 常用命令和 Shell 编程
熟悉 SQL，了解 MySQL 的安装和使用
具有 Hadoop、Zookeeper、Kafka 等大数据组件的集群环境搭建经验
熟悉 Hive SQL，了解 Hive 的安装搭建与使用
了解 Zookeeper、Flume、Kafka 组合的日志采集系统搭建
具有 MapReduce 程序开发经验，以及 Flume、Hive 自定义组件开发经验

## 个人作品

MapReduce 实现朴素贝叶斯： https://github.com/TomAndersen-cc/MyFirstHadoopProject
Flume/Kafka/Hive 自定义组件开发： https://github.com/TomAndersen-cc/HadoopCustomModules


## 项目经历

项目描述：
基于模拟用户行为日志数据，搭建日志数据采集平台
实现用户行为数据仓库的分层搭建，分为 ods、dwd、dws、ads 共计 4 层
针对数据仓库中的分层数据进行活跃用户数、新增用户数、留存用户数、沉默用户数等报表生成

整体设计：
数据传输层：使用 Flume Agent 监听日志文件，每条新增日志经过 Flume Interceptor 链过滤后传输到 Kafka 集群中，然后使用 Flume Agent 将 Kafka 中日志数据消费到 HDFS 中进行长期存储
数据存储层：HDFS 用于长期存储日志数据，MySQL 用于存储 Hive 元数据
数据计算层：在 Hive 中使用自定义的 UDTF 处理 HDFS 原始日志数据，然后进行数仓分层搭建，其中 Hive SQL 使用 Tez 作为执行引擎

涉及技术与框架：
Java、Hadoop、Zookeeper、Flume、Kafka、Hive、Tez、MySQL 等


## 其他

语言: 英语 (CET-6)，普通话二级乙等