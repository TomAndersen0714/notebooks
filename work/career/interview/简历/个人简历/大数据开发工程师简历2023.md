# 大数据开发工程师简历 2023


## 个人信息

性别：男，年龄：26 岁
电话：13409736469
邮箱： 13409736469@163.com
微信：TomAndersen
现居城市：四川省成都市


Github： https://github.com/TomAndersen0714
博客： https://blog.csdn.net/TomAndersen

照片：xxx

意向岗位：大数据开发工程师-数仓方向

## 教育经历

2019.09 - 2021.06，华中科技大学 - 计算机技术，硕士，计算机科学与技术学院
2015.09 - 2019.06，中国地质大学（武汉） - 空间信息与数字技术，本科，计算机科学与技术学院

## 专业技能

1. 了解 TCP/IP 协议族中 TCP、HTTP 等计算机网络基础通信协议
2. 了解 Linux Bash Shell 常用命令，具有 Shell 脚本开发经验
3. 熟悉 Java 编程语言，了解 JVM 基本原理，了解 Collection、JUC 等常用开发模块
4. 熟悉 Python 编程语言，了解 Loguru、SQLAlchemy 等常用开发模块
5. 熟悉 Airflow DAG 任务开发，熟悉 Airflow 自定义组件开发，具有 Airflow 源码开发经验
6. 了解 Pulsar、Kafka 消息队列，具有 Pulsar 相关开发经验
7. 熟悉 CDH、ClickHouse、Airflow 等大数据组件的部署和运维
8. 熟悉 ClickHouse SQL，熟悉 ClickHouse SQL 性能调优方法
9. 了解 HDFS、YARN、Hive、Spark 等大数据组件，了解 MR 开发框架，了解 Hive SQL 性能调优方法
10. 熟悉数仓搭建方法论，熟悉数仓优化常用方法，具有 ClickHouse 数仓搭建实践经验
11. 了解数据治理的基础理论，具有一定的数据治理开发实践经验

## 工作经历

工作时间：2022-07-01~至今
任职公司：晓多科技（成都晓多科技有限公司）
任职部门：大数据平台组
工作岗位：大数据开发工程师

工作职责：
1. 负责特定业务线的所有数据需求开发，其中包括 ETL 任务开发、数仓搭建、数据报表搭建、数据大屏搭建等。
2. 负责组内大数据开源组件运维，保障集群运行稳定。负责数据质量治理工具开发，编写数据治理规范和操作文档。
3. 负责组内大数据开发工具研发，提升组内数据开发能力和开发效率。

获奖情况：
1. 2022 年度奖项-突飞猛进奖-CEM 产品线团队（核心成员）
2. 2021 年度奖项-最佳协作奖（成员）
3. 2021 Q3-创新探索项目奖（成员）

## 项目经历

### 在线客服服务质量实时监控大屏


项目时间：2021-09~2021-11

项目介绍：为了赋能某电商运营企业，使其能够及时发现并介入在线客服的异常服务行为，提升和保证客服团队的整体服务质量。本项目基于客户的实时会话消息流，开发搭建了会话数据实时监控数据大屏，实现了客服接待过程中各项指标的实时更新、计算和可视化，为该运营商提供了在线客服服务质量的监控能力，提升了该企业整体客服的服务质量。最终实现，秒级近实时数据同步和查询，支撑了 100+ 企业，1500 +店铺下客服的在线服务质量监控。

相关组件：Pulsar、xdvector、ClickHouse、Airflow、DataForce 等
负责内容：
1. 数据集成：对接上游业务系统，使用内部自研流处理平台 xdvector 开发 Pulsar 消息消费程序，对客服实时会话日志数据进行 ETL，并实时写入 ClickHouse Buffer 表中，保证秒级数据写入。通过 Airflow 定期同步企业部门、员工、账号等维度数据到 ClickHouse 中。
2. 实时数仓搭建：ClickHouse 中采用 ReplacingReplicatedMergeTree 表引擎存储会话数据，保证数据高可用的同时，支持数据按照指定 ID 进行后台合并，配合 Merge On Read 机制以实现数据的近实时更新，后续通过 Distribued 表提供数据的实时查询。
3. 数据可视化：基于内部的低代码可视化平台 DataForce，以 ClickHouse 作为数据源，通过前端 EChars 组件，实现客服在线服务质量相关的实时和离线数据指标的计算和展示。

项目难点及解决思路：
1. 历史明细数据实时分析的性能问题。
	1. 一方面，在产品层面，通过和产品达成一致，约束数据更新的时间范围
	2. 另一方面，在技术层面，针对历史数据创建任务进行定期合并和统计指标落表，加速查询。
2. 基于 ClickHouse 的近实时更新方案的设计与实现。
	1. 通过技术调研，以及线下测试环境的性能对比测试，最终确定技术方案的实现路径，并将相关技术文档分享组内，实现技术沉淀。
项目总结与反思：
1. 开发需以终为始，尽量依据现实问题，不要人为设想伪命题，避免代码过度优化，增加后期运维成本，且影响项目整体进度。
2. 开发时，需提前预估数据量上限，做好性能评估，并提前和上游约定产品方案细则，否则后续变动时，客户大概率无法接受。

### 在线客服服务质量数据报表开发

项目介绍：为提升电商企业的客服服务质量，提升电商企业数据分析师的工作效率，本项目基于内部客服会话质检平台的质检结果，进行了离线质检数据报表的开发，通过离线统计服务质量相关数据指标，T+1 离线生成数据报表，通过 100+数据指标，为 400+企业、3000+店铺的客服团队服务质量评估、绩效考核、客服能力培训、数据分析报告等工作流提供了数据支撑和流程提效。

相关组件：MongoDB、ClickHouse、Airflow、DataForce 等

负责内容：
1. 数据集成和 ETL：对接上游客服质检业务系统，进行 MongoDB 数据集成的 ETL 任务开发，T+1 采集客服会话数据，并更新近期历史数据，以及客户企业店铺、员工、账号等配置数据。
2. 离线数仓搭建：基于客服质检、客服聊天会话等事实数据，以及商家客服相关的配置维度数据，采取分层的数据架构，基于该数据进行数据仓库搭建，支撑数据指标的生产。
3. 数据可视化：基于内部的低代码可视化平台，搭建可视化平台，展示数据指标，为电商客服团队的服务质量评估、绩效考核、客服能力培训、数据分析等活动出具相关数据报表。

项目难点：
1. 业务方面，初来乍到，产品迭代迅速，需要快速学习业务和产品相关知识。
2. 技术方面，参与人员众多、各平台代码、表结构参差不齐
项目总结与反思：
1. 可以使用四象限法给辅助待办事项排期，其中重要但不紧急的事项，如技术方案债务、需求开发债务这些重要的零碎事情，可以搜集起来按主题划分，之后拆分到日常迭代周期中进行解决。按主题划分，是为了避免做的事情不够聚焦，避免汇报时，无法提现工作量和价值；拆分排期，是为了尽量减小对于主线需求排期的影响，避免与主线需求冲突，导致项目延期。


### 数据同步和数据治理工具开发


// todo，airflow 数据治理也加入
// 难点：数据传输时序列化框架的选择、调度任务的实时监控和告警、数据质量定时监控和告警
// 反思：按照事件的重要和紧急程度，设置不同的处理策略

项目时间：202209~

项目介绍：某云服务器供应商因数据安全相关政策等原因，限制了服务器对外传输带宽，进而导致相关的服务集群被切分，数据服务无法统一出口，下游数据服务使用难度较大。为了解决数据服务出口统一的问题，提升数据服务效率，本项目通过采取异步传输的方式，将数据指标定时异步传输至外部环境，进而支撑统一的数据服务中心，并搭配相关的数据质量监控和预警，保证数据质量。

相关组件：Airflow、ClickHouse、Impala、Pulsar、SQLAlchemy、PostgreSQL 等  

负责内容：
1. 数据同步生产端开发：基于 Airflow 开发自定义组件，支持数据同步任务的定时调度，支持 Impala、ClickHouse 等数据库查询结果序列化并写入 Pulsar 消息队列，并实现幂等
2. 数据同步消费端开发：基于 Python 开发中间件服务，支持 Pulsar 数据反序列化并同步至对应数据库中
3. 数据质量监控模块: 修改 Airflow 源码, 将 Airflow 告警信息接入飞书群，实现线上调度任务的实时监控和预警；开发 Airflow 数据质量监控 DAG

项目难点：

项目总结与反思：
1. 应用层之上，再去兼容各方 API，属于重复造轮子，不如直接代理链接。

### 电商买家咨询热点统计

// todo：成果量化，一句话
// 难点：去重指标的统计
// 反思：

项目介绍：（一期）为了支撑和提效电商平台商家针对卖家咨询的问题进行的数据分析行为，利用分词工具，对客服的聊天数据进行分词，统计词频，抽取买家咨询热点，为电商商家提供数据分析方向。（二期）基于算法模型针对客服聊天会话数据的分类结果，搭建每日用户画像，统计中各个标签下的 UV、PV 等指标，同时支持用户下钻至原始会话，搭配大模型 AI 能力，增强和提效商家的数据分析能力。

相关组件：jiba、hanlp、LTP、LAC、Airflow、MongoDB、ElasticSearch、ClickHouse、DataForce 等

负责内容：
1. 技术调研：对比各个开源的中文文本分词工具，使用测试集进行评测
2. 数据集成和 ETL：基于 Airflow 定时使用开源分词工具将 ClickHouse 中的会话聊天数据进行分割，并将处理后的数据重新写入 ClickHouse
3. 离线数仓搭建：基于 ClickHouse 中通过分词处理后的聊天数据，搭建离线数仓，统计生产词频、咨询人数等指标
4. 数据可视化：基于内部的低代码可视化平台 Dataforce，通过词云等可视化组件，展示各个维度下的词频统计等指标。

## 职业证书

1. 计算机技术与软件专业技术资格-中级-软件设计师
2. DAMA 数据治理工程师（CDGA）
3. CDA 数据分析师（Level I）
4. CET-6 英语