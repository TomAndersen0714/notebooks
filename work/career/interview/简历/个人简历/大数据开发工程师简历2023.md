# 大数据开发工程师简历 2023


## 个人信息

性别：男，年龄：26 岁
电话：13409736469
邮箱： 13409736469@hust.edu.cn
微信：TomAndersen
现居城市：四川省成都市


个人主页： https://blog.tomandersen.cn/
Github： https://github.com/TomAndersen0714
博客： https://blog.csdn.net/TomAndersen

照片：xxx

意向岗位：大数据开发工程师-数仓方向

## 教育经历

2019.09 - 2021.06，华中科技大学 - 计算机技术，硕士，计算机科学与技术学院
2015.09 - 2019.06，中国地质大学（武汉） - 空间信息与数字技术，本科，计算机科学与技术学院

## 专业技能

1. 了解 TCP/IP、HTTP/HTTPS 等计算机网络基础通信协议
2. 了解 Linux Bash Shell 常用命令，具有 Shell 脚本开发经验
3. 了解 Java编程语言，了解 Java Collection、JUC 等基础开发框架，了解 JVM 基本原理
4. 了解 Python 编程语言，具有 loguru、SQLAlchemy 等开发经验
5. 了解 Pulsar、Kafka 消息队列，具有 Pulsar 相关开发经验
6. 熟悉 Airflow ETL 任务，以及 Airflow 自定义组件开发
7. 熟悉 CDH、ClickHouse、Airflow 等大数据组件的安装、部署和运维
8. 了解 HDFS、YARN、Hive 等经典大数据组件，了解 Hadoop MapReduce 开发框架
9. 了解 Hive SQL on Spark 的 SQL 调优
10. 熟悉 ClickHouse SQL，了解 ClickHouse SQL 性能调优
11. 熟悉数仓搭建方法论，具有 ClickHouse 数仓搭建经验
12. 了解数据治理的基础理论，具有一定的数据治理实践经验

## 工作经历

工作时间：2022-07-01~至今
任职公司：晓多科技（成都晓多科技有限公司）
任职部门：大数据平台组
工作岗位：大数据开发工程师
工作职责：
1. 负责特定业务线的所有数据需求开发，其中包括 ETL 任务开发、数仓搭建、数据报表搭建、数据大屏搭建等。
2. 负责组内大数据开源组件运维，保障集群运行稳定。负责数据质量治理工具开发，编写数据治理规范和操作文档。
3. 负责组内大数据开发工具研发，提升组内数据开发能力和开发效率。
获奖情况：
1. 2022 年度奖项-突飞猛进奖-CEM 产品线团队（核心成员）
2. 2021 年度奖项-最佳协作奖（成员）
3. 2021 Q3-创新探索项目奖（成员）

## 项目经历

### 在线客服服务质量实时监控大屏


项目时间：2021-09~2021-11

项目介绍：为了赋能某电商运营企业，使其能够及时发现并介入在线客服的异常服务行为，提升和保证客服团队的整体服务质量。本项目基于客户的实时会话消息流，开发搭建了会话数据实时监控数据大屏，实现了客服接待过程中各项指标的实时更新、计算和可视化，为该运营商提供了在线客服服务质量的监控能力，提升了该企业整体客服的服务质量。最终实现，秒级近实时数据同步和查询，支撑了 100+ 企业，1500 +店铺下客服的在线服务质量监控。

相关组件：Pulsar、xdvector、ClickHouse、Airflow、DataForce 等
负责内容：
1. 数据集成：使用内部自研流处理平台 xdvector 开发 Pulsar 消息消费程序，对客服实时会话日志数据进行 ETL，并实时写入 ClickHouse Buffer 表中，保证秒级数据写入。通过 Airflow 定期同步企业部门、员工、账号等维度数据到 ClickHouse 中。
2. 实时数仓搭建：ClickHouse 中采用 ReplacingReplicatedMergeTree 表引擎存储会话数据，保证数据高可用的同时，支持数据按照指定 ID 进行后台合并，配合 Merge On Read 机制以实现数据的近实时更新，后续通过 Distribued 表提供数据的实时查询。
3. 数据可视化：基于内部的低代码可视化平台 DataForce，以 ClickHouse 作为数据源，通过前端 EChars 组件，实现客服在线服务质量相关的实时和离线数据指标的计算和展示。
项目难点及解决思路：
1. 历史明细数据实时分析的性能问题。通过产品约束数据更新的时间范围，针对历史数据创建任务进行定期合并和统计指标落表，加速查询。
2. 基于 ClickHouse 的近实时更新方案的设计与实现。通过技术调研，以及线下测试环境的性能对比测试，最终确定技术方案的实现路径，并将相关技术文档分享组内，实现技术沉淀。
项目反思：
1. 开发需以终为始，尽量依据现实问题，不要人为设想伪命题，避免代码过度优化，增加后期运维成本，且影响项目整体进度。
2. 开发时，需提前预估数据量上限，做好性能评估，并提前和上游约定产品方案细则，否则后续变动时，客户大概率无法接受。

### 在线客服服务质量数据报表开发

// todo：成果量化，一句话
// 难点：参与人员众多、各平台代码、表结构参差不齐
// 反思：作为长期待办事项，日常迭代中排期解决。一方面是抛出问题，一方面是排期着手处理。

项目介绍：为提升各个电商企业的客服服务质量，，，并统计服务质量相关数据指标，同时基于指标定期生成各种数据报表，用于客服团队绩效考核、数据分析，以及工作汇报。

相关组件：MongoDB、ClickHouse、Airflow、DataForce 等

负责内容：
1. 数据集成和 ETL：对接上游客服质检业务系统，进行 MongoDB 数据集成的 ETL 任务开发
2. 离线数仓搭建：基于客服质检、客服聊天会话等事实数据，以及商家客服相关的维度数据，采取分层的数据架构，基于该数据进行数据仓库搭建，支撑数据指标的生产
3. 数据可视化：基于内部的低代码可视化平台，搭建可视化平台，展示数据指标，为商家的客服质检活动出具数据报表

### 电商买家咨询热点统计

// todo：成果量化，一句话
// 难点：去重指标的统计
// 反思：

项目介绍：（一期）为了支撑和提效电商平台商家针对卖家咨询的问题进行的数据分析行为，利用分词工具，对客服的聊天数据进行分词，统计词频，抽取买家咨询热点，为电商商家提供数据分析方向。（二期）基于算法模型针对客服聊天会话数据的分类结果，搭建每日用户画像，统计中各个标签下的 UV、PV 等指标，同时支持用户下钻至原始会话，搭配大模型 AI 能力，增强和提效商家的数据分析能力。

相关组件：jiba、hanlp、LTP、LAC、Airflow、MongoDB、ElasticSearch、ClickHouse、DataForce、Echarts 等

负责内容：
1. 技术方案概要设计：
2. 数据 ETL：对比各个开源的中文文本分词工具，使用测试集进行评测，并使用对应的模型，将商家客服的聊天数据进行定时离线处理并入库
3. 离线数仓搭建：基于处理后的聊天数据，搭建离线数仓，生产词频、咨询人数等指标
4. 数据可视化：基于内部的低代码可视化平台 DataForce，通过词云等可视化组件，展示数仓指标

### 数据同步和数据治理工具开发

基于 Airflow 的数据同步组件开发

// todo，airflow 数据治理也加入
// 难点：数据传输时序列化框架的选择、调度任务的实时监控和告警、数据质量定时监控和告警
// 反思：按照事件的重要和紧急程度，设置不同的处理策略

项目介绍：由于云服务供应商内部政策等原因，某电商平台的商家客服会话、商家订单等数据，被限制在特定的内网集群中，外网无法直接访问相关的数据服务，为了支持相关的数据需求开发，以及提供统一的上层数据服务，故开发一套数据同步工具，实现内外网的数据同步。

相关组件：Airflow、ClickHouse、Impala、Pulsar、SQLAlchemy、PostgreSQL 等  

负责内容：
数据生产模块开发：基于 Airflow 开发自定义组件，支持数据同步任务的定时调度，支持 Impala、ClickHouse 等数据库查询结果直接写入 Pulsar 消息队列
数据消费模块开发：基于 Python 开发中间件服务，支持 Pulsar 数据幂等同步

## 职业证书

1. 计算机技术与软件专业技术资格-中级-软件设计师
2. DAMA 数据治理工程师（CDGA）
3. CDA 数据分析师（Level I）
4. CET-6 英语