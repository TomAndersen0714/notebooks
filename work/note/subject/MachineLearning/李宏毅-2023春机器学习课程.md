# 李宏毅-2023春机器学习课程-学习笔记



## GPT-4有哪些神奇的能力？

1. 相比于GPT-3.5，支持图片输入和解析
2. 相比于GPT-3.5，各种考试中的成绩提升明显
3. 相比于GPT-3.5，结果更收敛
4. 相比于GPT-3.5，支持更多的语言


## 如何低开销复刻ChatGPT

### 为什么需要搭建自己的ChatGPT Model？

OpenAI官方明确回复，在使用OpenAI的ChatGPT过程中，可能会使用用户数据进行训练，且删除私人数据过程繁琐，即无法保证数据的安全性。

### 复刻思路-Knowledge Distillation

基于ChatGPT来生成成对的输入输出数据集，基于这些数据集来训练新的模型，使得新模型尽量接近ChatGPT的结果。

### 一些常见的ChatGPT复刻模型

LLaMA、Alpaca、Vicuna

Dolly 2.0

由于LLaMA模型的License不支持商用，同时OpenAI ChatGPT官方使用条文中明确说明，不能使用ChatGPT的输出内容，用于训练与其存在竞争关系的模型，故而还出现了Dolly 2.0这类支持商用的模型。

### Model Self-improve的一种思路

1. self-consistency，即多次自我提问，取频率最高作为最终正确答案，进而提升准确率
2. 使用self-consistency生成的数据集，循环训练Model，进一步提升准确率


## 让AI村民组成虚拟村庄会发生什么事？

https://www.bilibili.com/video/BV1TD4y137mP?p=47&vd_source=31f9517734e43a6c180d5d1d56a5e162


## 速览图像生成常见模型

图像生成模型的输出方式，与语言生成模型最大的不同之处在于，图像生成模型通常需要针对很多细节部分进行大量的自动补充。

### 常见思路

**逐个击破（如Aoto-regressive）**：基于像素点的概率分布（Distribution），来选择后续的像素点，缺点是比较耗费时间

**一次到位**：相比“逐个击破”，更加快捷，但缺点是各个Pixel之间的相关性无法保证，可能生成奇怪的图片

**目前常用的图像生成技巧**：在高维度向量分布（Distribution）中随机抽样（Random Sample）出高维向量（Vector）对应到某个图像（Image）上，以此来标识各个图像，辅助图像生成。

**目前常用的图像生成模型**：
Variational Auto-encoder（VAE）
Flow-based Generative Model
Diffusion Model
Generative Adversarial Network（GAN）

## DDPM

### Diffusion Model是如何运作的

Reverse Process：生成由随机像素组成的初始图片，然后不断进行降噪（Denoise），最后生成目标图片

Denoise：输入图片，以及此图片的Noise度量值；基于输入的参数，通过Noise Predicter生成出输入图片对应的Noise，然后将输入图片减去生成的Noise，其结果作为最后的输出

Noise Predictor：是一种模型，用于预测给定图像中的噪声（Noise）

### 如何训练Noise Predictor

Forward Process（Diffusion Process）：基于原始图片，Random Sample生成Noise图片，便可以产生Noise Predictor的训练集，便可以训练Noise Predictor

### Text-to-Image的方式

在Denoise步骤，需要支持额外的输入参数Text，来约束生成的图像


## Stable Diffusion、DALL-E、Imagen背后共同的套路


Text Encoder：将输入的文字转换为向量

Generation Model：输入向量、Noise，生成一个中间产物，某个图片的压缩结果

Decoder：将图片的压缩结果，转换为目标图片


### 图像生成类Model的评价指标

FID主要关注生成图像的分布与真实图像的分布之间的差异程度，而CLIP则用于图像与文本之间的语义匹配程度。


## 参考链接
1. [Bilibili-李宏毅春季机器学习课程](https://www.bilibili.com/video/BV1TD4y137mP)
2. https://github.com/Fafa-DL/Lhy_Machine_Learning