# 李宏毅-机器学习2021版课程-学习笔记


## Machine Learning

Machine Learning ≈ 确定某个特殊的Function（函数），其具有特定的输入和输出

### Function的类别

**Regression**
Regression: 输入一个序列，输出一个标量（Scalar）

**Classification**
Classification：输入类别（Class）或选项（Option），输出正确的选项或类别

Alpha Go，就是一种Classification，其中class就是棋盘的位置

**Structure Learning**
Structure Learning：输出的内容是结构化的，如图片、文档等


### 确定Function的步骤


**第一步**：确定带有未知参数的Function，即**确定Model**

基于Domain Knowledge，推测出带参Function的函数式，即推测Model。如一元二次函数、三元四次函数等，线性Model，或者多项式回归、神经网络等非线性Model

其中已知的先验数据集中，**feature**代表数据的数值，**label**则代表数据的分类


**第二步**：基于Training Data和Model，确定**Loss Function**

Loss Function是基于Training Data，构建出的函数，用于判断Model参数的好坏

Loss Function其输入是Model参数的一组数值，输出的标量，即**误差error或loss**，代表着Model参数的好坏

Loss Function中常常会基于MAE（mean absolute error）、MSE（mean square error）等方式，来计算误差error

以Loss Function的一组输入参数为超平面（hyperplane）坐标，可以是任意（维度）数量的，以error的值作为此超平面的法向量的长度，进而构成的多维空间中的曲面，被称为**误差曲面（error surface）**


**第三步**：最优化**Optimization**，即**确定最优Parameter**

最优Parameter：使得Loss值最小的Parameter

Gradient Descent（梯度下降）方法：
随机选取一个起始点，然后通过计算Loss Function中误差曲面（error surface）的微分（即二维的斜率），以便朝着Loss下降最快的方向调整参数，进而逐渐确定Loss最小值。

机器学习过程中，需要自己手动设置的参数，如learning rate等，被称为**Hyperparameter**



## Deep Learning

深度学习是一种以人工神经网络为基础的机器学习方法，属于机器学习的一个分支，一个具体的实现方法。

其中人工神经网络就是机器学习中的一种Model，神经网络中的每个神经元（Neuron）可以看做是一个函数（Function），一组神经元组成一个层次（Layer），而多个层次共同组成一个神经网络（Neural Network）。

深度学习中的深度（Deep），代表着神经网络模型中的层数较多，即网络中包含多个隐含层的情况。

Function => Neuron

Neurons => Layer

Layers => Neural Network

Deep = Many hidden layers（隐含层）

每个隐含层的输出，是下一个隐含层的输入


## 机器学习Model优化攻略

先检查Training Data Loss，如果Training Data Loss很大，则可能是Model Bias，或者是Optimization的问题。

如果Training Data Loss很小，则检查Testing Data Loss。

如果Testing Data Loss很大，则可能是Overfitting，或者Mismatch的问题。

反之，如果Testing Data Loss和Testing Data Loss都很小，则代表Model很好。


### Model Bias

如果Training Loss结果太大，则可能是Model Bias的问题。

通常情况下，是因为Model过于简单，导致拟合效果太差，预测结果与真实结果相差太大。

常见的解决方案是重新设计Model，采取更加复杂的Model，如：增加更多的Layer等。



### Optimization Issue

可以通过对比模型，来诊断是否是Optimization环节的问题：层次更多的Model，但是Loss却大于层次更少的Model，可以推断是Optimization的问题。

1. 使用层次少的网络构建Model，或者其他能够容易进行optimization的Model，用于后续对照
2. 使用层次多的网络构建Model，如果在相同Training Data的前提下，Deeper Network Model相比于层次少的Model的Loss更高，则可以推断是Optimization的问题

常用解决方案：
1. 更换Optimization方法，以选取确定更好的Parameter

### Overfitting

可以通过对比Training Data和Testing Data下，如果Loss的Training Data下的计算结果，远小于Testing Data，则可以推断是Overfitting的问题。

常用解决方案：
1. 增大Training Data
	1. Data augmentation，如图片放大缩小、左右反转等
	2. 采集新数据
2. 降低Model的灵活度和复杂度
	1. Less parameter, share parameters
	2. Less features
	3. Early stopping
	4. Regularization
	5. Dropout

Training Data的Loss一般会随着Model复杂度的提升，而不断减小，但Testing Data的Loss会先随着Model复杂度的提升而减小，当突破某阈值之后，便会随着Model复杂度的提升而增加，进而出现Overfitting的问题，即Testing Loss要远大于Training Loss。


### Mismatch

Mismatch指的是Training Set和Testing Set在分布上的区别太大，进而使得Testing Loss数值明显大于Training Loss。


### 如何选出最好的Model

Cross Validation

将Training Set分成Training Set和Validation Set，使用Training Set训练Model完成之后，可以使用Validation Set去验证Model，相当于提前验证Model。

避免最后在应用Testing Set时结果不如意。


## Optimization

通过Hessian矩阵的计算结果，可以判断当前遇到的critical point问题到底是local minima，还是saddle point的问题。


## 参考链接
1. [李宏毅-【機器學習2021】(中文版)](https://www.youtube.com/playlist?list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J)