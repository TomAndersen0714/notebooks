# 机器学习基础概念

## 基础概念

机器学习，简单理解就是确定一个函数，不同的函数所能接收的参数和输出不同


## 机器学习分类

根据函数输出内容来分类：

### 回归（Regression）

回归（Regression）：函数的输出是一个数值

### 分类（Classification）

分类（Classification）：函数的输出是一个类别（标签），即是一个选择题，选择已有的一个标签

### 生成式学习（Structured Learning、Generative Learning）

生成式学习（Structured Learning、Generative Learning）：生成有结构的数据，如影像、语句

ChatGPT实际上解决的是分类（Classification）问题，但却是将生成式学习拆分为分类问题进行求解


## 确定模型的步骤


### 确定模型要解决的问题

确定机器学习要解决的问题，输入输出分别是什么

### 设定模型类别候选范围

确定候选模型（Model）的集合，一般使用大写H表示。

训练集越小，模型类别的候选范围就越小，反之则越大。


#### 深度学习（Deep Learning）

如深度学习（Deep Learning）中类神经网络的结构（CNN、RNN、Transformer等）指的就是不同的候选函数集合

CNN、Self-attention适合图像处理。


#### 决策树（Decision Tree）
如决策树（Decision Tree）等


### 设定模型评价标准

设定，评价函数好坏的标准。

PS: 在训练集中损失函数结果小的，在测试集中结果不一定好，因为训练集和测试集差距未知。


#### 监督学习（Supervised Learning）

通常会使用损失函数（Loss function），使用大写L表示，来评估函数的好坏，数值越大代表距离真实越远。

如：L(f1)=15，其中f1是待评估函数。

损失函数（Loss Function）是基于训练集（Training Set）生成的


#### 半监督学习（Semi-supervised Learning）

训练集（Training Set）并不能完全覆盖测试集（Test Set）时，损失函数不会仅基于训练集来计算结果。

如：L(f1) = f1输出与正确答案的差距，或者当输入类似时f1输出之间的差距


#### 强化学习（Reinforcement Learning）



### 确定最好的模型

找出最好的函数，即最优化（Optimization），使用的工具是最佳化演算法（Optimization Algorithm）

即在函数集合（H）中，使用损失函数Loss，来评估各个模型，选择损失函数结果最小的模型，这一过程即最优化（Optimization）

机器学习常说的调参，指的是超参数（Hyperparameter）


#### 梯度下降（Gradient Descent）

如：梯度下降（Gradient Descent）中（Adam、AdamW等）


#### 遗传算法（Genetic Algorithm）

如：遗传算法（Genetic Algorithm）


## 生成模型的步骤


### 训练集


### 测试集



## 参考链接
1. [李宏毅-【生成式AI】快速了解機器學習基本原理](https://www.youtube.com/watch?v=phQK8xZpgoU)