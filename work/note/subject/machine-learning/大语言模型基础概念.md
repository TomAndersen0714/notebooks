## 大语言模型基础概念


GPT是文字接龙，BERT是文字填空。


## 对于大语言模型的期待

### 成为专才（Finetune）

成为专才，好处是在单一任务上表现突出，如BERT

#### 对预训练模型做改造

##### Head

外挂

##### Finetune

微调

##### Adapter

插件


### 成为全才(Prompt)

成为全才，只需要重新设计Prompt就可以快速开发新功能，通过自然语言就实现开发，如ChatGPT

#### In-content learning



#### Instruction-tuning



## 总结
大语言模型在使用时通常会运用不同的技术来应对不同的需求和场景，例如Finetune和Prompt。

通过Finetune技术，可以对大型数据模型进行微调，使得大语言模型在某一单一任务上表现出色，但该过程的开发周期相对较长。

而使用Prompt技术，则可以通过自然语言指令来控制模型生成的内容。在面对各种需求时，只需要重新设计Prompt，就可以快速开发新的功能。

## 参考链接
1. [2023 - 李宏毅 - 对大型语言模型的两种不同期待](https://www.bilibili.com/video/BV1hv4y1G7M2)